{
  "permissions": {
    "allow": [
      "Bash(npx tsc:*)",
      "Bash(pnpm --filter @autoart/forms add:*)",
      "Bash(pnpm run build:*)",
      "Bash(pnpm build:shared:*)",
      "Bash(pnpm --filter autoart-backend build:*)",
      "Bash(pnpm --filter autoart-frontend build:*)",
      "Bash(pnpm build:frontend:*)",
      "Bash(npx vite build)",
      "Bash(node -e:*)",
      "Bash(npx vite:*)",
      "Bash(pnpm list:*)",
      "Bash(pnpm install:*)",
      "Bash(node:*)",
      "Bash(pnpm db:status:*)",
      "Bash(ls:*)",
      "Bash(git ls-tree:*)",
      "Bash(git rev-parse:*)",
      "Bash(git checkout:*)",
      "Bash(git pull:*)",
      "Bash(git rm:*)",
      "Bash(git mv:*)",
      "Bash(npm install:*)",
      "Bash(pnpm why:*)",
      "Bash(powershell -Command:*)",
      "Bash(Remove-Item -Recurse -Force dist -ErrorAction SilentlyContinue)",
      "Bash(pnpm --filter backend exec tsc:*)",
      "Bash(if not exist \"c:\\\\Users\\\\silen\\\\Documents\\\\automatiq\\\\autoart\\\\design-briefs\" mkdir \"c:\\\\Users\\\\silen\\\\Documents\\\\automatiq\\\\autoart\\\\design-briefs\")",
      "Bash(npx eslint:*)",
      "Bash(git push:*)",
      "Bash(gh pr list:*)",
      "Bash(gh pr merge:*)",
      "Bash(git add:*)",
      "Bash(python -c:*)",
      "Bash(grep:*)",
      "Bash(python -m ruff check:*)",
      "Bash(mypy:*)",
      "Bash(ruff check:*)",
      "Bash(ruff format:*)",
      "Bash(python -m py_compile:*)",
      "Bash(python -m pytest:*)",
      "Bash(tee:*)",
      "Bash(uv run ruff check:*)",
      "Bash(pnpm build:*)",
      "Bash(git branch:*)",
      "Bash(git remote prune:*)",
      "Bash(git show:*)",
      "WebFetch(domain:visjs.github.io)",
      "WebFetch(domain:raw.githubusercontent.com)",
      "Bash(pnpm --filter autoart-frontend list:*)",
      "Bash(pnpm --filter autoart-frontend ls:*)",
      "Bash(echo:*)",
      "Bash(pnpm i)",
      "Bash(pnpm config:*)",
      "Bash(DEBUG=*)",
      "Bash(npm --version:*)",
      "Bash(pnpm exec tsc:*)",
      "Bash(move backendsrcmodulesimportsservices_session-status.service.ts backendsrcmodulesimportsservicessession-status.service.ts)",
      "Bash(pnpm --filter frontend build:*)",
      "Bash(cmd /c \"npx tsc --noEmit 2>&1\")",
      "Bash(pnpm --filter @autoart/shared build:*)",
      "Bash(pnpm tsc:*)",
      "Bash(curl:*)",
      "Bash(gh issue create --title \"Feature: Gemini Vision API deep crawl fallback for image extraction\" --body \"$\\(cat <<''EOF''\n## Summary\n\nAdd an optional **Gemini Vision API deep crawl** as a fallback when pattern-based adapter extraction yields poor results.\n\n## Problem\n\nCurrent adapter-based extraction relies on pattern matching \\(CSS selectors, regex, JSON parsing\\). This works well for known platforms but can miss images on:\n- Custom-built portfolio sites\n- Sites with unusual DOM structures  \n- JavaScript-heavy galleries that don''t embed URLs in HTML\n- Sites where adapter confidence is low\n\n## Proposed Solution\n\nAdd a `GeminiDeepCrawler` that uses Gemini 2.0 Flash''s vision capabilities to:\n\n1. **Validate extracted images** - Confirm which URLs are actual artwork vs UI elements/icons\n2. **Find missed images** - Analyze rendered page screenshot to identify additional artwork\n3. **Extract metadata** - Use vision to read artist names, titles, etc. from complex layouts\n\n### Trigger Conditions\n\nDeep crawl activates when:\n- Adapter confidence < 0.5\n- Pattern extraction found < 3 images\n- User explicitly enables \"deep crawl\" mode\n\n### Integration Point\n\n```python\n# In WebCollector.collect\\(\\) after adapter extraction:\nif deep_crawl_config.enabled:\n    result = await maybe_deep_crawl\\(\n        config=deep_crawl_config,\n        url=source,\n        html=html,\n        soup=soup,\n        adapter_name=adapter.name,\n        adapter_confidence=match.confidence,\n        images_found=image_urls,\n    \\)\n    if result and result.additional_image_urls:\n        image_urls.extend\\(result.additional_image_urls\\)\n```\n\n## Implementation Requirements\n\n### Dependencies\n- `google-generativeai` package\n- Screenshot capture \\(Playwright or Puppeteer for headless rendering\\)\n- API key configuration in settings\n\n### Files to Modify/Create\n\n| File | Action |\n|------|--------|\n| `adapters/gemini_deep_crawl.py` | Implement \\(mockup exists\\) |\n| `collectors/web.py` | Add integration call |\n| `types.py` | Add `DeepCrawlConfig` to runner config |\n| Settings/API config | Add Gemini API key field |\n\n### API Design\n\n```python\n@dataclass\nclass DeepCrawlConfig:\n    enabled: bool = False\n    api_key: str | None = None\n    model: str = \"gemini-2.0-flash\"\n    min_images_threshold: int = 3\n    min_confidence_threshold: float = 0.5\n\n@dataclass  \nclass DeepCrawlResult:\n    additional_image_urls: list[str]\n    validated_image_urls: list[str]\n    rejected_image_urls: list[str]\n    extracted_metadata: dict\n    confidence: float\n    tokens_used: int\n```\n\n## Mockup Location\n\nA placeholder implementation exists at:\n`apps/autohelper/autohelper/modules/runner/adapters/gemini_deep_crawl.py`\n\n## Tasks\n\n- [ ] Add Playwright/Puppeteer integration for screenshots\n- [ ] Implement Gemini API client wrapper\n- [ ] Build structured prompts for image validation\n- [ ] Add configuration UI for API key\n- [ ] Integrate into WebCollector flow\n- [ ] Add cost estimation \\(tokens per page\\)\n- [ ] Add rate limiting and error handling\n- [ ] Write tests with mocked API responses\n\n## Labels\n\n`enhancement`, `runner`, `ai-integration`\nEOF\n\\)\")"
    ]
  }
}
